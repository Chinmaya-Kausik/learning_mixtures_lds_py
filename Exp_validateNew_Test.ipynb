{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "287b17d2",
   "metadata": {},
   "source": [
    "# Testing with original model_estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e362d6f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Oct 21 19:12:03 2022\n",
    "\n",
    "@author: soominkwon\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import generate_models, compute_autocovariance, generate_mixed_lds, compute_separation\n",
    "from classification import classification\n",
    "from subspace_est import subspace_estimation\n",
    "from clustering import clustering_fast\n",
    "from model_estimation import model_estimation\n",
    "from helpers import get_clusters, model_errors\n",
    "import time\n",
    "\n",
    "# initializing parameters\n",
    "d   = 30\n",
    "K   = 4\n",
    "rho = 0.5\n",
    "\n",
    "Msubspace        = 30  * d\n",
    "Mclustering      = 10 * d\n",
    "Mclassification  = 50 * d\n",
    "M = Msubspace + Mclustering + Mclassification\n",
    "\n",
    "Tsubspace        = 20\n",
    "Tclustering      = 20\n",
    "Tclassification  = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a941cba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrials = 6\n",
    "block_num = 15\n",
    "\n",
    "# initializing lists for errors\n",
    "all_trials_A = np.zeros((Ntrials, block_num+1))\n",
    "all_trials_W = np.zeros((Ntrials, block_num+1))\n",
    "\n",
    "for trial in range(Ntrials):\n",
    "    print('Trial Number:', trial)\n",
    "    # generating labels and lengths of trajectories\n",
    "    true_labels = np.random.randint(0, K, (M, 1))\n",
    "\n",
    "    Ts = np.concatenate([np.ones((Msubspace, 1))*Tsubspace, np.ones((Mclustering,1))*Tclustering,\n",
    "                         np.ones((Mclassification, 1))*Tclassification], axis=0)\n",
    "    \n",
    "    # generating synthetic data\n",
    "    As, Whalfs = generate_models(d=d, K=K, rho=rho)\n",
    "\n",
    "    # squaring Ws\n",
    "    Ws = []\n",
    "    for k in range(K):\n",
    "        Ws.append(Whalfs[k]**2)\n",
    "    \n",
    "    # generating synthetic data\n",
    "    Gammas, Ys = compute_autocovariance(As=As, Whalfs=Whalfs)\n",
    "    delta_gy = compute_separation(Gammas=Gammas, Ys=Ys)\n",
    "    data = generate_mixed_lds(As=As, Whalfs=Whalfs, true_labels=true_labels, Ts=Ts)\n",
    "    \n",
    "    data_subspace = data[:Msubspace]\n",
    "    data_clustering = data[Msubspace:(Msubspace+Mclustering)]\n",
    "    data_classification = data[(Msubspace+Mclustering):]\n",
    "\n",
    "    print('Synthetic Data Generated')\n",
    "    \n",
    "    # coarse subspace estimation\n",
    "    Vs, Us = subspace_estimation(data_sub_est=data_subspace, K=K)\n",
    "    print('Coarse Subspace Estimated')\n",
    "    \n",
    "    # clustering\n",
    "    labels_clustering, S_orig, S = clustering_fast(data=data_clustering, Vs=Vs, Us=Us, K=K, tau=delta_gy/4,\n",
    "                                        no_subspace=0)\n",
    "    print('Coarse Labels Clustered')\n",
    "\n",
    "    print(labels_clustering)\n",
    "\n",
    "    # getting the data corresponding to clusters\n",
    "    clusters = get_clusters(data=data_clustering, labels=labels_clustering.squeeze(), K=K)\n",
    "\n",
    "    # determine permutation\n",
    "    subtl = true_labels[Msubspace:(Msubspace+Mclustering)]\n",
    "    perm = np.zeros((K, 1)) # true label -> estimated label\n",
    "    invperm = np.zeros((K, 1)) # estimated label -> true label\n",
    "    visited = []\n",
    "    for k in range(K):\n",
    "        idx = (subtl == k)*1\n",
    "        tmp = []\n",
    "        for val in range(len(idx)):\n",
    "            if idx[val] == 1:\n",
    "                tmp.append(labels_clustering[val])\n",
    "        tmpint = 0\n",
    "        if(tmp and (round(np.median(tmp)) not in visited)):\n",
    "            tmpint = round(np.median(tmp))\n",
    "            visited.append(tmpint)\n",
    "        else:\n",
    "            print(\"Msub = \", Msubspace)\n",
    "            raise NotImplementedError(\"Bad data\")\n",
    "        perm[k] = tmpint\n",
    "        invperm[tmpint] = k\n",
    "\n",
    "    start = time.time()\n",
    "    # coarse model estimation\n",
    "    Ahats, Whats = model_estimation(clusters)\n",
    "    print('Coarse Models Estimated')\n",
    "\n",
    "    # computing initial model errors\n",
    "    A_error, W_error = model_errors(Ahats=Ahats, As=As, Whats=Whats, Ws=Ws, invperm=invperm)\n",
    "    print('Initial A Error:', A_error)\n",
    "    print('Initial W Error:', W_error)\n",
    "\n",
    "    # initializing error lists\n",
    "    errors_A = [A_error]\n",
    "    errors_W = [W_error]\n",
    "\n",
    "    # classification\n",
    "    tmpidx = np.linspace(5, np.log(Mclassification), block_num).T\n",
    "    tmpidx = np.ceil(np.exp(tmpidx))\n",
    "    tmpidx[len(tmpidx)-1] = Mclassification\n",
    "    tmpidx = np.insert(tmpidx, 0, 0)\n",
    "    T_coarse = Tclustering * Mclustering\n",
    "    T_refined = T_coarse + Tclassification * tmpidx\n",
    "\n",
    "    \n",
    "    # going through all block iterations\n",
    "    for j in range(block_num):\n",
    "        print(\"Block Iteration: \", j)\n",
    "        idx1 = int(tmpidx[j])\n",
    "        idx2 = int(tmpidx[j+1])\n",
    "\n",
    "        newdata = data_classification[idx1:idx2] # data for classification\n",
    "\n",
    "        # coarse model classification\n",
    "        newlabels = classification(data_classification=newdata, Ahats=Ahats, Whats=Whats)\n",
    "        newlabels = newlabels\n",
    "\n",
    "        new_clusters = get_clusters(data=newdata, labels=newlabels.squeeze(), K=K)\n",
    "        #print(len(new_clusters[0]), len(new_clusters[1]), len(new_clusters[2]), print(len(new_clusters[3])))\n",
    "        \n",
    "        # adding new clusters to data\n",
    "        for k in range(K):\n",
    "            tmp = new_clusters[k]\n",
    "            clusters[k] = clusters[k] + tmp\n",
    "            \n",
    "        # refining models\n",
    "        refined_Ahats, refined_Whats = model_estimation(clusters)\n",
    "        refined_err_Ahats, refined_err_Whats = model_errors(Ahats=refined_Ahats, As=As,\n",
    "                                                            Whats=refined_Whats, Ws=Ws, invperm=invperm)\n",
    "\n",
    "        print(\"Refined A Error: \", refined_err_Ahats)\n",
    "        print(\"Refined W Error: \", refined_err_Whats)\n",
    "\n",
    "        # appending errors\n",
    "        errors_A.append(refined_err_Ahats)\n",
    "        errors_W.append(refined_err_Whats)\n",
    "    \n",
    "    end = time.time()\n",
    "    print('Exec time is ', end-start)\n",
    "    \n",
    "    all_trials_A[trial, :] = np.asarray(errors_A)\n",
    "    all_trials_W[trial, :] = np.asarray(errors_W)\n",
    "\n",
    "\n",
    "A_errors_mean = np.mean(all_trials_A, axis=0)\n",
    "W_errors_mean = np.mean(all_trials_W, axis=0)\n",
    "scales = np.sqrt(K*d / T_refined)\n",
    "\n",
    "plt.rc('font', family='serif')\n",
    "plt.plot(T_refined, A_errors_mean.T, 'blue',marker='o')\n",
    "plt.plot(T_refined, W_errors_mean.T, 'orange', marker='*')\n",
    "plt.plot(T_refined, scales, 'black', linestyle='--')\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.grid(True, 'both')\n",
    "plt.legend(['A', 'W', '$\\sqrt{Kd/T}$'])\n",
    "plt.show()\n",
    "\n",
    "np.savez('A_errors.npz', all_trials_A)\n",
    "np.savez('W_errors.npz', all_trials_W)\n",
    "np.savez('T_refined.npz', T_refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d942f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3bc949e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a103138c",
   "metadata": {},
   "source": [
    "# Testing with pseudo vectorized model_estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ae2878a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Oct 21 19:12:03 2022\n",
    "\n",
    "@author: soominkwon\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import generate_models, compute_autocovariance, generate_mixed_lds, compute_separation\n",
    "from classification import classification\n",
    "from subspace_est import subspace_estimation\n",
    "from clustering import clustering_fast\n",
    "from model_estimation_pseudoVectorized import model_estimation\n",
    "from helpers import get_clusters, model_errors\n",
    "import time\n",
    "\n",
    "# initializing parameters\n",
    "d   = 30\n",
    "K   = 4\n",
    "rho = 0.5\n",
    "\n",
    "Msubspace        = 30  * d\n",
    "Mclustering      = 10 * d\n",
    "Mclassification  = 50 * d\n",
    "M = Msubspace + Mclustering + Mclassification\n",
    "\n",
    "Tsubspace        = 20\n",
    "Tclustering      = 20\n",
    "Tclassification  = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd763299",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrials = 6\n",
    "block_num = 15\n",
    "\n",
    "# initializing lists for errors\n",
    "all_trials_A = np.zeros((Ntrials, block_num+1))\n",
    "all_trials_W = np.zeros((Ntrials, block_num+1))\n",
    "\n",
    "for trial in range(Ntrials):\n",
    "    print('Trial Number:', trial)\n",
    "    # generating labels and lengths of trajectories\n",
    "    true_labels = np.random.randint(0, K, (M, 1))\n",
    "\n",
    "    Ts = np.concatenate([np.ones((Msubspace, 1))*Tsubspace, np.ones((Mclustering,1))*Tclustering,\n",
    "                         np.ones((Mclassification, 1))*Tclassification], axis=0)\n",
    "    \n",
    "    # generating synthetic data\n",
    "    As, Whalfs = generate_models(d=d, K=K, rho=rho)\n",
    "\n",
    "    # squaring Ws\n",
    "    Ws = []\n",
    "    for k in range(K):\n",
    "        Ws.append(Whalfs[k]**2)\n",
    "    \n",
    "    # generating synthetic data\n",
    "    Gammas, Ys = compute_autocovariance(As=As, Whalfs=Whalfs)\n",
    "    delta_gy = compute_separation(Gammas=Gammas, Ys=Ys)\n",
    "    data = generate_mixed_lds(As=As, Whalfs=Whalfs, true_labels=true_labels, Ts=Ts)\n",
    "    \n",
    "    data_subspace = data[:Msubspace]\n",
    "    data_clustering = data[Msubspace:(Msubspace+Mclustering)]\n",
    "    data_classification = data[(Msubspace+Mclustering):]\n",
    "\n",
    "    print('Synthetic Data Generated')\n",
    "    \n",
    "    # coarse subspace estimation\n",
    "    Vs, Us = subspace_estimation(data_sub_est=data_subspace, K=K)\n",
    "    print('Coarse Subspace Estimated')\n",
    "    \n",
    "    # clustering\n",
    "    labels_clustering, S_orig, S = clustering_fast(data=data_clustering, Vs=Vs, Us=Us, K=K, tau=delta_gy/4,\n",
    "                                        no_subspace=0)\n",
    "    print('Coarse Labels Clustered')\n",
    "\n",
    "    print(labels_clustering)\n",
    "\n",
    "    # getting the data corresponding to clusters\n",
    "    clusters = get_clusters(data=data_clustering, labels=labels_clustering.squeeze(), K=K)\n",
    "    \n",
    "    # determine permutation\n",
    "    subtl = true_labels[Msubspace:(Msubspace+Mclustering)]\n",
    "    perm = np.zeros((K, 1)) # true label -> estimated label\n",
    "    invperm = np.zeros((K, 1)) # estimated label -> true label\n",
    "    visited = []\n",
    "    for k in range(K):\n",
    "        idx = (subtl == k)*1\n",
    "        tmp = []\n",
    "        for val in range(len(idx)):\n",
    "            if idx[val] == 1:\n",
    "                tmp.append(labels_clustering[val])\n",
    "        tmpint = 0\n",
    "        if(tmp and (round(np.median(tmp)) not in visited)):\n",
    "            tmpint = round(np.median(tmp))\n",
    "            visited.append(tmpint)\n",
    "        else:\n",
    "            print(\"Msub = \", Msubspace)\n",
    "            raise NotImplementedError(\"Bad data\")\n",
    "        perm[k] = tmpint\n",
    "        invperm[tmpint] = k\n",
    "\n",
    "    start = time.time()\n",
    "    # coarse model estimation\n",
    "    listOfClusters = [clusters]\n",
    "    for clusters in listOfClusters:\n",
    "        print(clusters[0].shape)\n",
    "    Ahats, Whats = model_estimation(listOfClusters)\n",
    "    print('Coarse Models Estimated')\n",
    "\n",
    "    # computing initial model errors\n",
    "    A_error, W_error = model_errors(Ahats=Ahats, As=As, Whats=Whats, Ws=Ws, invperm=invperm)\n",
    "    print('Initial A Error:', A_error)\n",
    "    print('Initial W Error:', W_error)\n",
    "\n",
    "    # initializing error lists\n",
    "    errors_A = [A_error]\n",
    "    errors_W = [W_error]\n",
    "\n",
    "    # classification\n",
    "    tmpidx = np.linspace(5, np.log(Mclassification), block_num).T\n",
    "    tmpidx = np.ceil(np.exp(tmpidx))\n",
    "    tmpidx[len(tmpidx)-1] = Mclassification\n",
    "    tmpidx = np.insert(tmpidx, 0, 0)\n",
    "    T_coarse = Tclustering * Mclustering\n",
    "    T_refined = T_coarse + Tclassification * tmpidx\n",
    "\n",
    "    \n",
    "    # going through all block iterations\n",
    "    for j in range(block_num):\n",
    "        print(\"Block Iteration: \", j)\n",
    "        idx1 = int(tmpidx[j])\n",
    "        idx2 = int(tmpidx[j+1])\n",
    "\n",
    "        newdata = data_classification[idx1:idx2] # data for classification\n",
    "\n",
    "        # coarse model classification\n",
    "        newlabels = classification(data_classification=newdata, Ahats=Ahats, Whats=Whats)\n",
    "        newlabels = newlabels\n",
    "\n",
    "        new_clusters = get_clusters(data=newdata, labels=newlabels.squeeze(), K=K)\n",
    "        #print(len(new_clusters[0]), len(new_clusters[1]), len(new_clusters[2]), print(len(new_clusters[3])))\n",
    "        \n",
    "        # adding new clusters to data\n",
    "        listOfClusters.append(new_clusters)\n",
    "            \n",
    "        # refining models\n",
    "        refined_Ahats, refined_Whats = model_estimation(listOfClusters)\n",
    "        refined_err_Ahats, refined_err_Whats = model_errors(Ahats=refined_Ahats, As=As,\n",
    "                                                            Whats=refined_Whats, Ws=Ws, invperm=invperm)\n",
    "\n",
    "        print(\"Refined A Error: \", refined_err_Ahats)\n",
    "        print(\"Refined W Error: \", refined_err_Whats)\n",
    "\n",
    "        # appending errors\n",
    "        errors_A.append(refined_err_Ahats)\n",
    "        errors_W.append(refined_err_Whats)\n",
    "    \n",
    "    end = time.time()\n",
    "    print('Exec time is ', end-start)\n",
    "    \n",
    "    all_trials_A[trial, :] = np.asarray(errors_A)\n",
    "    all_trials_W[trial, :] = np.asarray(errors_W)\n",
    "\n",
    "\n",
    "A_errors_mean = np.mean(all_trials_A, axis=0)\n",
    "W_errors_mean = np.mean(all_trials_W, axis=0)\n",
    "scales = np.sqrt(K*d / T_refined)\n",
    "\n",
    "plt.rc('font', family='serif')\n",
    "plt.plot(T_refined, A_errors_mean.T, 'blue',marker='o')\n",
    "plt.plot(T_refined, W_errors_mean.T, 'orange', marker='*')\n",
    "plt.plot(T_refined, scales, 'black', linestyle='--')\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.grid(True, 'both')\n",
    "plt.legend(['A', 'W', '$\\sqrt{Kd/T}$'])\n",
    "plt.show()\n",
    "\n",
    "np.savez('A_errors.npz', all_trials_A)\n",
    "np.savez('W_errors.npz', all_trials_W)\n",
    "np.savez('T_refined.npz', T_refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "677533ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "141a4fa2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2b58bfe1",
   "metadata": {},
   "source": [
    "# Testing with vectorized model_estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89c3c382",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Fri Oct 21 19:12:03 2022\n",
    "\n",
    "@author: soominkwon\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from utils import generate_models, compute_autocovariance, generate_mixed_lds, compute_separation\n",
    "from classification import classification\n",
    "from subspace_est import subspace_estimation\n",
    "from clustering import clustering_fast\n",
    "from model_estimation_vectorized import model_estimation\n",
    "from helpers import get_clusters, model_errors\n",
    "import time\n",
    "\n",
    "# initializing parameters\n",
    "d   = 30\n",
    "K   = 4\n",
    "rho = 0.5\n",
    "\n",
    "Msubspace        = 30  * d\n",
    "Mclustering      = 10 * d\n",
    "Mclassification  = 50 * d\n",
    "M = Msubspace + Mclustering + Mclassification\n",
    "\n",
    "Tsubspace        = 20\n",
    "Tclustering      = 20\n",
    "Tclassification  = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85909499",
   "metadata": {},
   "outputs": [],
   "source": [
    "Ntrials = 6\n",
    "block_num = 15\n",
    "\n",
    "# initializing lists for errors\n",
    "all_trials_A = np.zeros((Ntrials, block_num+1))\n",
    "all_trials_W = np.zeros((Ntrials, block_num+1))\n",
    "\n",
    "for trial in range(Ntrials):\n",
    "    print('Trial Number:', trial)\n",
    "    # generating labels and lengths of trajectories\n",
    "    true_labels = np.random.randint(0, K, (M, 1))\n",
    "\n",
    "    Ts = np.concatenate([np.ones((Msubspace, 1))*Tsubspace, np.ones((Mclustering,1))*Tclustering,\n",
    "                         np.ones((Mclassification, 1))*Tclassification], axis=0)\n",
    "    \n",
    "    # generating synthetic data\n",
    "    As, Whalfs = generate_models(d=d, K=K, rho=rho)\n",
    "\n",
    "    # squaring Ws\n",
    "    Ws = []\n",
    "    for k in range(K):\n",
    "        Ws.append(Whalfs[k]**2)\n",
    "    \n",
    "    # generating synthetic data\n",
    "    Gammas, Ys = compute_autocovariance(As=As, Whalfs=Whalfs)\n",
    "    delta_gy = compute_separation(Gammas=Gammas, Ys=Ys)\n",
    "    data = generate_mixed_lds(As=As, Whalfs=Whalfs, true_labels=true_labels, Ts=Ts)\n",
    "    \n",
    "    data_subspace = data[:Msubspace]\n",
    "    data_clustering = data[Msubspace:(Msubspace+Mclustering)]\n",
    "    data_classification = data[(Msubspace+Mclustering):]\n",
    "\n",
    "    print('Synthetic Data Generated')\n",
    "    \n",
    "    # coarse subspace estimation\n",
    "    Vs, Us = subspace_estimation(data_sub_est=data_subspace, K=K)\n",
    "    print('Coarse Subspace Estimated')\n",
    "    \n",
    "    # clustering\n",
    "    labels_clustering, S_orig, S = clustering_fast(data=data_clustering, Vs=Vs, Us=Us, K=K, tau=delta_gy/4,\n",
    "                                        no_subspace=0)\n",
    "    print('Coarse Labels Clustered')\n",
    "\n",
    "    print(labels_clustering)\n",
    "\n",
    "    # getting the data corresponding to clusters\n",
    "    clusters = get_clusters(data=data_clustering, labels=labels_clustering.squeeze(), K=K)\n",
    "\n",
    "    # determine permutation\n",
    "    subtl = true_labels[Msubspace:(Msubspace+Mclustering)]\n",
    "    perm = np.zeros((K, 1)) # true label -> estimated label\n",
    "    invperm = np.zeros((K, 1)) # estimated label -> true label\n",
    "    visited = []\n",
    "    for k in range(K):\n",
    "        idx = (subtl == k)*1\n",
    "        tmp = []\n",
    "        for val in range(len(idx)):\n",
    "            if idx[val] == 1:\n",
    "                tmp.append(labels_clustering[val])\n",
    "        tmpint = 0\n",
    "        if(tmp and (round(np.median(tmp)) not in visited)):\n",
    "            tmpint = round(np.median(tmp))\n",
    "            visited.append(tmpint)\n",
    "        else:\n",
    "            print(\"Msub = \", Msubspace)\n",
    "            raise NotImplementedError(\"Bad data\")\n",
    "        perm[k] = tmpint\n",
    "        invperm[tmpint] = k\n",
    "\n",
    "    start = time.time()\n",
    "    # coarse model estimation\n",
    "    Ahats, Whats = model_estimation(clusters)\n",
    "    print('Coarse Models Estimated')\n",
    "\n",
    "    # computing initial model errors\n",
    "    A_error, W_error = model_errors(Ahats=Ahats, As=As, Whats=Whats, Ws=Ws, invperm=invperm)\n",
    "    print('Initial A Error:', A_error)\n",
    "    print('Initial W Error:', W_error)\n",
    "\n",
    "    # initializing error lists\n",
    "    errors_A = [A_error]\n",
    "    errors_W = [W_error]\n",
    "\n",
    "    # classification\n",
    "    tmpidx = np.linspace(5, np.log(Mclassification), block_num).T\n",
    "    tmpidx = np.ceil(np.exp(tmpidx))\n",
    "    tmpidx[len(tmpidx)-1] = Mclassification\n",
    "    tmpidx = np.insert(tmpidx, 0, 0)\n",
    "    T_coarse = Tclustering * Mclustering\n",
    "    T_refined = T_coarse + Tclassification * tmpidx\n",
    "\n",
    "    \n",
    "    # going through all block iterations\n",
    "    for j in range(block_num):\n",
    "        print(\"Block Iteration: \", j)\n",
    "        idx1 = int(tmpidx[j])\n",
    "        idx2 = int(tmpidx[j+1])\n",
    "\n",
    "        newdata = data_classification[idx1:idx2] # data for classification\n",
    "\n",
    "        # coarse model classification\n",
    "        newlabels = classification(data_classification=newdata, Ahats=Ahats, Whats=Whats)\n",
    "        newlabels = newlabels\n",
    "\n",
    "        new_clusters = get_clusters(data=newdata, labels=newlabels.squeeze(), K=K)\n",
    "        #print(len(new_clusters[0]), len(new_clusters[1]), len(new_clusters[2]), print(len(new_clusters[3])))\n",
    "        \n",
    "        # adding new clusters to data\n",
    "        for k in range(K):\n",
    "            tmp = new_clusters[k]\n",
    "            clusters[k] = clusters[k] + tmp\n",
    "            \n",
    "        # refining models\n",
    "        refined_Ahats, refined_Whats = model_estimation(clusters)\n",
    "        refined_err_Ahats, refined_err_Whats = model_errors(Ahats=refined_Ahats, As=As,\n",
    "                                                            Whats=refined_Whats, Ws=Ws, invperm=invperm)\n",
    "\n",
    "        print(\"Refined A Error: \", refined_err_Ahats)\n",
    "        print(\"Refined W Error: \", refined_err_Whats)\n",
    "\n",
    "        # appending errors\n",
    "        errors_A.append(refined_err_Ahats)\n",
    "        errors_W.append(refined_err_Whats)\n",
    "    \n",
    "    end = time.time()\n",
    "    print('Exec time is ', end-start)\n",
    "    \n",
    "    all_trials_A[trial, :] = np.asarray(errors_A)\n",
    "    all_trials_W[trial, :] = np.asarray(errors_W)\n",
    "\n",
    "\n",
    "A_errors_mean = np.mean(all_trials_A, axis=0)\n",
    "W_errors_mean = np.mean(all_trials_W, axis=0)\n",
    "scales = np.sqrt(K*d / T_refined)\n",
    "\n",
    "plt.rc('font', family='serif')\n",
    "plt.plot(T_refined, A_errors_mean.T, 'blue',marker='o')\n",
    "plt.plot(T_refined, W_errors_mean.T, 'orange', marker='*')\n",
    "plt.plot(T_refined, scales, 'black', linestyle='--')\n",
    "plt.xscale(\"log\")\n",
    "plt.yscale(\"log\")\n",
    "plt.grid(True, 'both')\n",
    "plt.legend(['A', 'W', '$\\sqrt{Kd/T}$'])\n",
    "plt.show()\n",
    "\n",
    "np.savez('A_errors.npz', all_trials_A)\n",
    "np.savez('W_errors.npz', all_trials_W)\n",
    "np.savez('T_refined.npz', T_refined)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071fd511",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
